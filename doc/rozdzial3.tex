\chapter{Analiza dostępnych rozwiązań}
\label{cha:analiza}

W rozdziale tym omówione zostaną wybrane dotychczasowo opracowane metody.

%---------------------------------------------------------------------------

\section{Flux Tensor with Split Gaussian Models}
\label{sec:FTSG}

Jednym z zaproponowanych rozwiązań omawianego w tej pracy problemu jest fuzja dwóch metod detekcji zmian na sekwencji wideo \cite{6910016}. Polega ona na wyliczeniu tensora przepływu (ang. \textit{Flux Tensor}) i modelowaniu tła za pomocą algorytmu bazującego na GMM opisanego w sekcji \ref{sec:GMM} ze zmienną liczbą modeli, dostosowującą się automatycznie przestrzennie i czasowo.
Metoda ta dzieli się na trzy główne moduły:
\begin{itemize}
\item
detekcja zmian na poziomie piksela - obliczane są osobno modele dla ruchu (\textit{flux tensor} - FT) i dla zmian jasności/kolorów na obrazie (\textit{split Gaussian model} - SG)
\item
fuzja otrzymanych wyników - stosując odpowiednie reguły łączone są modele FT i SG, aby zredukować ilość fałszywych detekcji
\item
klasyfikacja obiektów - obsługa przypadków obiektów zatrzymanych bądź usuniętych ze sceny
\subsection{Flux Tensor}
Tensor przepływu pozwala na wykrycie ruchu pomiędzy kolejnymi ramkami nagrania. 
\end{itemize}
\section{Weightless Neutral Networks}
Praca \cite{6910014}
\section{Self-tuning Background Subtraction Algorithm}
\label{sec:BinWang}
Choć w ostatnich latach możliwości obliczeniowe maszyn, zarówno pod względem ilości przetwarzanych danych, jak i prędkości, rozwijały się bardzo dynamicznie, obecni inżynierowie borykają się z problemami nie do przezwyciężenia. Częstotliwość taktowania procesorów o dotychczas stosowanej architekturze nie może być już bardziej zwiększana - spowodowane jest to fizycznymi ograniczeniami sprzętu. Sekwencyjne wykonywanie poleceń uzależnia więc czas działania algorytmu od prędkości obliczeniowej jednostki wykonującej operacje. Dla problemu opisywanego w tej pracy szybkość przetwarzania jest szczególnie ważna - standardowy format wideo to 25 klatek na sekundę. Oznacza to, iż w celu detekcji w czasie rzeczywistym, jedna ramka o określonej rozdzielczości musi zostać przetworzona w czasie 1/25 sekundy. Dlatego też autorzy rozwiązania opisanego w artykule \cite{6910012} postanowili zmierzyć się z tym problemem, opracowując metodę, która wykonuje potrzebne obliczenia dla każdego piksela niezależnie, dokonując klasyfikacji jedynie na podstawie historii jego jasności. Takie podejście umożliwia implementację w architekturze równoległej, jak choćby z wykorzystaniem mocy obliczeniowej GPU (ang. \textit{Graphics processing unit} - procesor graficzny) czy układów FPGA (ang. \textit{Field-programmable gate array}).

\section{SuBSENSE}
Zaletą metody przedstawionej w \cite{stflexible} jest brak konieczności testowania algorytmu dla każdego obserwowanego otoczenia w celu dostosowania parametrów dających najlepsze wyniki. Ze względu na mechanizm sprzężenia zwrotnego, zastosowany w tym podejściu, są one dostosowywane automatycznie, pozwalając uzyskać bardzo dobre wyniki nawet w zmieniających się warunkach. Jest to kolejna z metod opierających się na subtrakcji tła, postanowiono jednak podejść do tego zagadnienia w nieco inny sposób.
\subsection{LBSP}
W odróżnieniu od standardowego rozwiązania polegającego na porównywaniu kolorów pomiędzy kolejnymi ramkami, autorzy rozwiązania zdecydowali się wykorzystać metodę LBSP \cite{bilodeau2013change} (ang. \textit{Local Binary Similarity Patterns}), pozwalającą zastąpić informację o barwie piksela pewnymi deskryptorami, lepiej odzwierciedlającymi jego cechy. Dzięki temu mechanizm subtrakcji tła daje lepsze efekty. Wiele podejść stosowanych w innych rozwiązaniach bazuje na obliczaniu odległości euklidesowej pomiędzy poziomami jasności pikseli na wybranych fragmentach obrazu, jednak takie rozwiązanie często prowadzi do problemów z detekcją ruchu obiektów zajmujących duże obszary na scenie - spowodowane jest to jednorodnym charakterem powierzchni, przez co zmiana nie jest rejestrowana. Zbadano, iż LBSP lepiej radzi sobie z tym problemem. Ponadto, działania na wartościach binarnych są operacjami bardzo szybkimi, co zmniejsza znacznie czas detekcji.
\paragraph{}
Wyznaczanie lokalnego binarnego wzorca podobieństwa odbywa się na dwóch płaszczyznach - wewnątrz rozważanego regionu osobno dla każdej z analizowanych ramek oraz tegoż regionu pomiędzy ramkami. Porównywane są tu wartości piksela centralnego obszaru z pikselami sąsiadującymi. Analizowany fragment R ma rozmiar \textit{n} x \textit{n}, brane pod uwagę piksele sąsiedztwa (nie wszystkie wartości muszą być analizowane, niekiedy porównuje się wybiórczo) oznaczono jako P. Wyznaczanie LBSP odbywa się na podstawie niniejszego wzoru:
\begin{equation}
LBSP_{R}(x_{c},y_{c}) = 
\sum_{p=0}^{P-1}d(i_{p}-i_{c})2^p
\end{equation},
gdzie
\begin{equation}
d(x)=\left\{\substack{
1 \, \, \mathrm{dla} \, \, |x|\leq T_{d} \\
0 \, \, \mathrm{dla} \, \, |x|>T_{d}}\right.
\end{equation}
, przy czym Td jest progiem podobieństwa, ip - analizowanym pikselem sąsiedztwa P, ic - pikselem centralnym obszaru.\\
Centralny piksel może być wybrany zarówno z obszaru, z którego pochodzi analizowane sąsiedztwo, jak i z innego regionu - na tym samym obrazie bądź z innej ramki.
\subsubsection{Subtrakcja tła}
Subtrakcja tła z pomocą LBSP odbywa się na podstawie porównania obecnej ramki z modelem uzyskanym z F pierwszych. 
\paragraph{Faza inicjalizacyjna \\}
Analiza pierwszej ramki opiera się na wyznaczeniu LBSP  jest jedynie wewnątrz obszaru (ip i ic znajdują się na tej samej ramce). Dla regionu 5 x 5 z wybranymi pikselami sąsiedztwa w liczbie 16 otrzymywane są w ten sposób 16-bitowe wyniki. Ponieważ dla każdego kanału (R, G i B) LBSP wyznaczane jest osobno, po połączeniu uzyskuje się ciąg 48-bitowy. Jeśli w sekwencji testowej dany ciąg powtórzony jest przynajmniej B razy, region oznaczony zostaje jako tło. W modelu M zapisane zostają wartości jasności odpowiadających wzorcowi pikseli. Następnie poddane analizie zostają kolejne ramki ze zbioru F, na podstawie których dokonuje się aktualizacji modelu tła. Po fazie inicjalizacyjnej model pozostaje niezmienny.
\paragraph{Detekcja obiektów \\}
Detekcja obiektów odbywa się na zasadzie porównywania kolejnych ramek z modelem tła. LBSP wyznaczane jest tutaj międzyramkowo, to znaczy piksele ip brane są z aktualnej ramki, ic - z odpowiadającego piksela tła. Decyzja o tym, gdzie piksel ma zostać zaklasyfikowany (bg - tło, fg - pierwszy plan), podejmowana jest w następujący sposób:
\begin{equation}
L_{f}(x,y)=\left\{\substack{
bg \, \, H(LBSP_{f}(x,y),LBSP_{M}(x,y))\leq T_{h} \\
fg \, \, H(LBSP_{f}(x,y),LBSP_{M}(x,y))>T_{h}}\right.
\end{equation}
\section{Spectral-360}
W pracy \cite{6910013}


